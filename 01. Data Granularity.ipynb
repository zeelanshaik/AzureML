{"cells":[{"cell_type":"markdown","source":["# Selecting Data Granularity Appropriate to the Hypothesis"],"metadata":{}},{"cell_type":"markdown","source":["##Azure Machine Learning workspace"],"metadata":{}},{"cell_type":"markdown","source":["It is a logical container for your machine learning experiments, compute target, datastore, machine learning models, docker images, deployed services...\n\nKeeps them all together for teams to collaborate"],"metadata":{}},{"cell_type":"markdown","source":["### Create an Azure Machine learning workspace"],"metadata":{}},{"cell_type":"code","source":["# Check core SDK version number\nimport azureml.core\nfrom azureml.core import Workspace\nfrom azureml.core import Dataset\n\nprint('SDK version:', azureml.core.VERSION)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">SDK version: 1.0.74\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# azureml-core of version 1.0.72 or higher is required\nfrom azureml.core import Workspace\n\ntry:\n  ws = Workspace.create(\n    name=\"your-workspace-name\", \n    subscription_id='your-subscription-id', \n    resource_group='your-resource-group'\n    location='your-preferred-location'\n  )\n  print('workspace configuration succeeded')\nexcept:\n  print('Workspace not found')\n  \nws.name"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["###Use an existing workspace"],"metadata":{}},{"cell_type":"code","source":["# azureml-core of version 1.0.72 or higher is required\nfrom azureml.core import Workspace, Dataset\n\nsubscription_id = 'your-subscription-id'\nresource_group = 'your-resource-group'\nworkspace_name = 'your-workspace-name'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\nworkspace.name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>&apos;customer_360_ws&apos;\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Use Datasets directly in training"],"metadata":{}},{"cell_type":"markdown","source":["### Create a TabularDataset"],"metadata":{}},{"cell_type":"markdown","source":["By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred.\n\nEvery workspace comes with a default datastore (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and create Dataset from it. We will now upload the Iris data to the default datastore (blob) within your workspace."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["try:\n  dataset = Dataset.get_by_name(workspace, name='Flight Delays Data')\n  file = dataset.download(target_path='/train-dataset/flight_data', overwrite=True)\n  print('File target path {}'.format(file))\nexcept:\n  print('Not completed')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">File target path [&apos;/train-dataset/flight_data/Flight Delays Data.csv&apos;]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["datastore = workspace.get_default_datastore()\ndatastore.upload_files(files = file,\n                       target_path = '/train-dataset/Flight Delays Data/',\n                       overwrite = True,\n                       show_progress = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Uploading an estimated of 1 files\nUploading /train-dataset/flight_data/Flight Delays Data.csv\nUploaded /train-dataset/flight_data/Flight Delays Data.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n<span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>$AZUREML_DATAREFERENCE_103a02d77c774dadb53c3b197c305d64\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, '/train-dataset/test_file/Flight Delays Data.csv')])\n\n# preview the first 3 rows of the dataset\ndf = dataset.to_pandas_dataframe()\ndf.describe()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">8</span><span class=\"ansired\">]: </span>\n            Year         Month    DayofMonth     DayOfWeek  OriginAirportID  DestAirportID    CRSDepTime      DepDelay      DepDel15    CRSArrTime      ArrDelay      ArrDel15     Cancelled\ncount  2719418.0  2.719418e+06  2.719418e+06  2.719418e+06     2.719418e+06   2.719418e+06  2.719418e+06  2.691974e+06  2.691974e+06  2.719418e+06  2.690385e+06  2.719418e+06  2.719418e+06\nmean      2013.0  6.979968e+00  1.579747e+01  3.898391e+00     1.274226e+04   1.274246e+04  1.326645e+03  1.053687e+01  2.023419e-01  1.505270e+03  6.637688e+00  2.166316e-01  1.067618e-02\nstd          0.0  1.984331e+00  8.799860e+00  1.985988e+00     1.501973e+03   1.501969e+03  4.713766e+02  3.609953e+01  4.017458e-01  4.939662e+02  3.864881e+01  4.119496e-01  1.027726e-01\nmin       2013.0  4.000000e+00  1.000000e+00  1.000000e+00     1.014000e+04   1.014000e+04  1.000000e+00 -6.300000e+01  0.000000e+00  1.000000e+00 -9.400000e+01  0.000000e+00  0.000000e+00\n25%       2013.0  5.000000e+00  8.000000e+00  2.000000e+00     1.129200e+04   1.129200e+04  9.200000e+02 -4.000000e+00  0.000000e+00  1.120000e+03 -1.100000e+01  0.000000e+00  0.000000e+00\n50%       2013.0  7.000000e+00  1.600000e+01  4.000000e+00     1.289200e+04   1.289200e+04  1.320000e+03 -1.000000e+00  0.000000e+00  1.528000e+03 -3.000000e+00  0.000000e+00  0.000000e+00\n75%       2013.0  9.000000e+00  2.300000e+01  6.000000e+00     1.405700e+04   1.405700e+04  1.725000e+03  9.000000e+00  0.000000e+00  1.918000e+03  1.000000e+01  0.000000e+00  0.000000e+00\nmax       2013.0  1.000000e+01  3.100000e+01  7.000000e+00     1.537600e+04   1.537600e+04  2.359000e+03  1.863000e+03  1.000000e+00  2.359000e+03  1.845000e+03  1.000000e+00  1.000000e+00\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["###Basic statistical description of airlines"],"metadata":{}},{"cell_type":"markdown","source":["As a first step, we consider all the flights from all carriers. Here, the aim is to classify the airlines with respect to \ntheir punctuality and for that purpose, we compute a few basic statisticial parameters:"],"metadata":{}},{"cell_type":"code","source":["#__________________________________________________________________\n# function that extract statistical parameters from a grouby objet:\ndef calc_stats(group):\n    return {'min': group.min(), 'max': group.max(),\n            'count': group.count(), 'mean': group.mean()}\n  \n  \n#_______________________________________________________________\n# Creation of a dataframe with statitical infos on each airline:\nglobal_stats = df['DepDelay'].groupby(df['Carrier']).apply(calc_stats).unstack()\nglobal_stats = global_stats.sort_values('count')\nglobal_stats"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>\n            count     max       mean   min\nCarrier                                   \nHA        18636.0  1847.0   1.151052 -23.0\nVX        34795.0   765.0  14.352407 -21.0\nF9        35765.0   789.0  12.110275 -63.0\nYV        51870.0   662.0   9.544920 -31.0\nAS        68907.0   654.0   0.625365 -25.0\n9E        78110.0   710.0   9.734131 -25.0\nFL        92430.0  1113.0  10.185265 -49.0\nMQ       109556.0  1244.0  15.538912 -60.0\nB6       121764.0   537.0  12.621719 -30.0\nEV       154007.0   838.0  14.489478 -52.0\nOO       158537.0   773.0   7.882684 -45.0\nUS       233283.0   860.0   4.944338 -24.0\nUA       285363.0   787.0  12.583842 -27.0\nAA       288282.0  1863.0  12.064007 -28.0\nDL       384402.0  1165.0   7.362576 -25.0\nWN       576267.0   608.0  12.838167 -16.0\n</div>"]}}],"execution_count":18}],"metadata":{"name":"01. Data Granularity","notebookId":3522181963930457},"nbformat":4,"nbformat_minor":0}
